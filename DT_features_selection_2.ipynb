{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969d8738-4a5a-4be2-9f64-9981fe95f705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance by sklearn: {'manufacturer': 0.0, 'company_location': 0.139, 'year_reviewed': 0.086, 'bean_origin': 0.0, 'bar_name': 0.068, 'cocoa_percent': 0.164, 'num_ingredients': 0.0, 'ingredients': 0.152, 'review': 0.39}\n",
      "The accuracy is:  77.86561264822134 %\n",
      "Execution time in seconds: 0.046859025955200195\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "##data loaded\n",
    "data=pd.read_csv('chocolate_bars.csv',index_col=0)\n",
    "data.head(-5)\n",
    "##filing the missing datas\n",
    "#filling the missing tables with the most common ingredients\n",
    "data['ingredients'].fillna(data['ingredients'].mode()[0], inplace=True)\n",
    "data['num_ingredients'].fillna(data['num_ingredients'].mode()[0], inplace=True)\n",
    "#print(data)\n",
    "\n",
    "# Importing LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Instantiating LabelEncoder\n",
    "le=LabelEncoder()\n",
    "# Iterating over all the values of each column and extract their dtypes\n",
    "for col in data.columns.to_numpy():\n",
    "    # Comparing if the dtype is object\n",
    "    if data[col].dtypes in ('object','category'):\n",
    "    # Using LabelEncoder to do the numeric transformation\n",
    "        data[col]=le.fit_transform(data[col].astype(str))\n",
    "        \n",
    "#Binning the rating column\n",
    "cut_labels = ['really bad', 'bad', 'ok', 'good']\n",
    "cut_bins = [0, 0.99,1.99,2.99,4.0]\n",
    "data['rating'] = pd.cut(data['rating'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "\n",
    "#creating the testing and training variables\n",
    "x=data.drop(\"rating\",axis=1)\n",
    "y=data[\"rating\"]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42,stratify=y)\n",
    "x_train.shape, x_test.shape\n",
    "\n",
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Saving the feature names \n",
    "features = x.columns.tolist()\n",
    "\n",
    "import time\n",
    "startTime = time.time()\n",
    "##Decision tree\n",
    "dt=DecisionTreeClassifier(max_depth=5,random_state=42,criterion=\"gini\",splitter=\"best\",min_samples_split=10,max_leaf_nodes=15)\n",
    "dt.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "# Extracting the importances by sklearn \n",
    "importances_sk = dt.feature_importances_\n",
    "feature_importance_sk = {}\n",
    "for i, feature in enumerate(features):\n",
    "    feature_importance_sk[feature] = round(importances_sk[i], 3)\n",
    "    \n",
    "print(f\"Feature importance by sklearn: {feature_importance_sk}\")\n",
    "\n",
    "\n",
    "\n",
    "#Evaluate the accuracy of the model\n",
    "y_pred = dt.predict(x_test)\n",
    "predictions = metrics.accuracy_score(y_test, y_pred)\n",
    "#Calculating the accuracy in percentage\n",
    "print('The accuracy is: ', predictions * 100, '%')\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45af9f6c-3403-4cb4-a1f6-d38a057d92e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      company_location  year_reviewed  bar_name  cocoa_percent  ingredients  \\\n",
      "id                                                                            \n",
      "2454                62           2019       750           76.0           10   \n",
      "2458                62           2019      1597           76.0           10   \n",
      "2454                62           2019       162           76.0           10   \n",
      "2542                62           2021       935           68.0           10   \n",
      "2546                62           2021      1418           72.0           10   \n",
      "...                ...            ...       ...            ...          ...   \n",
      "1205                 3           2014      1249           80.0            6   \n",
      "1996                 3           2017        11           75.0           10   \n",
      "2036                 3           2018       487           75.0           10   \n",
      "2170                 3           2018      1008           70.0           10   \n",
      "2170                 3           2018       953           72.0           10   \n",
      "\n",
      "      review  \n",
      "id            \n",
      "2454    1679  \n",
      "2458     319  \n",
      "2454     288  \n",
      "2542     229  \n",
      "2546     742  \n",
      "...      ...  \n",
      "1205    2452  \n",
      "1996    2220  \n",
      "2036     741  \n",
      "2170     756  \n",
      "2170    1396  \n",
      "\n",
      "[2530 rows x 6 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1771, 6), (759, 6))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating reduced vectors\n",
    "x=data.drop(columns=['rating', 'manufacturer','bean_origin','num_ingredients'])\n",
    "y=data[\"rating\"]\n",
    "print(x)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42,stratify=y)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d95d2aea-6f63-4308-b694-0ad2065dfaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  77.86561264822134 %\n",
      "Execution time in seconds: 0.02352142333984375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "startTime = time.time()\n",
    "##Decision tree\n",
    "dt=DecisionTreeClassifier(max_depth=5,random_state=42,criterion=\"gini\",splitter=\"best\",min_samples_split=10,max_leaf_nodes=15)\n",
    "dt.fit(x_train,y_train)\n",
    "\n",
    "#Evaluate the accuracy of the model\n",
    "y_pred = dt.predict(x_test)\n",
    "predictions = metrics.accuracy_score(y_test, y_pred)\n",
    "#Calculating the accuracy in percentage\n",
    "print('The accuracy is: ', predictions * 100, '%')\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8ed21-a878-4889-8da1-13974fd00b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
